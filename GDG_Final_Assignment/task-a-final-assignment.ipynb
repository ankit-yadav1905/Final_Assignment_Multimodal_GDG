{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10701818,"sourceType":"datasetVersion","datasetId":6632105}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.007023Z","iopub.execute_input":"2025-02-09T17:49:52.007320Z","iopub.status.idle":"2025-02-09T17:49:52.307182Z","shell.execute_reply.started":"2025-02-09T17:49:52.007292Z","shell.execute_reply":"2025-02-09T17:49:52.306324Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/multimodal-sentiment/Multimodal_dataset_assignment3/labels.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.308243Z","iopub.execute_input":"2025-02-09T17:49:52.308563Z","iopub.status.idle":"2025-02-09T17:49:52.347949Z","shell.execute_reply.started":"2025-02-09T17:49:52.308510Z","shell.execute_reply":"2025-02-09T17:49:52.347149Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.349496Z","iopub.execute_input":"2025-02-09T17:49:52.349781Z","iopub.status.idle":"2025-02-09T17:49:52.361582Z","shell.execute_reply.started":"2025-02-09T17:49:52.349761Z","shell.execute_reply":"2025-02-09T17:49:52.360804Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0    image_name  \\\n0           0   image_1.jpg   \n1           1  image_2.jpeg   \n2           2   image_3.JPG   \n3           3   image_4.png   \n4           4   image_5.png   \n\n                                            text_ocr  \\\n0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n1  The best of #10 YearChallenge! Completed in le...   \n2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n3              10 Year Challenge - Sweet Dee Edition   \n4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n\n                                      text_corrected      humour  \\\n0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n1  The best of #10 YearChallenge! Completed in le...   not_funny   \n2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n3              10 Year Challenge - Sweet Dee Edition  very_funny   \n4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n\n           sarcasm       offensive      motivational overall_sentiment  \n0          general   not_offensive  not_motivational     very_positive  \n1          general   not_offensive      motivational     very_positive  \n2    not_sarcastic   not_offensive  not_motivational          positive  \n3  twisted_meaning  very_offensive      motivational          positive  \n4     very_twisted  very_offensive  not_motivational           neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>image_name</th>\n      <th>text_ocr</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>image_1.jpg</td>\n      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>image_2.jpeg</td>\n      <td>The best of #10 YearChallenge! Completed in le...</td>\n      <td>The best of #10 YearChallenge! Completed in le...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>image_3.JPG</td>\n      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>image_4.png</td>\n      <td>10 Year Challenge - Sweet Dee Edition</td>\n      <td>10 Year Challenge - Sweet Dee Edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>image_5.png</td>\n      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"df.isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.362820Z","iopub.execute_input":"2025-02-09T17:49:52.363115Z","iopub.status.idle":"2025-02-09T17:49:52.376845Z","shell.execute_reply.started":"2025-02-09T17:49:52.363084Z","shell.execute_reply":"2025-02-09T17:49:52.375988Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0             0\nimage_name             0\ntext_ocr             161\ntext_corrected         5\nhumour                 0\nsarcasm                0\noffensive              0\nmotivational           0\noverall_sentiment      0\ndtype: int64"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.377589Z","iopub.execute_input":"2025-02-09T17:49:52.377917Z","iopub.status.idle":"2025-02-09T17:49:52.389638Z","shell.execute_reply.started":"2025-02-09T17:49:52.377877Z","shell.execute_reply":"2025-02-09T17:49:52.389009Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Index(['Unnamed: 0', 'image_name', 'text_ocr', 'text_corrected', 'humour',\n       'sarcasm', 'offensive', 'motivational', 'overall_sentiment'],\n      dtype='object')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"df = df.drop(columns=['Unnamed: 0','text_ocr'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.390425Z","iopub.execute_input":"2025-02-09T17:49:52.390707Z","iopub.status.idle":"2025-02-09T17:49:52.400192Z","shell.execute_reply.started":"2025-02-09T17:49:52.390680Z","shell.execute_reply":"2025-02-09T17:49:52.399406Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df = df.dropna()\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.400968Z","iopub.execute_input":"2025-02-09T17:49:52.401172Z","iopub.status.idle":"2025-02-09T17:49:52.419766Z","shell.execute_reply.started":"2025-02-09T17:49:52.401154Z","shell.execute_reply":"2025-02-09T17:49:52.419182Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"     image_name                                     text_corrected  \\\n0   image_1.jpg  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n1  image_2.jpeg  The best of #10 YearChallenge! Completed in le...   \n2   image_3.JPG  Sam Thorne @Strippin ( Follow Follow Saw every...   \n3   image_4.png              10 Year Challenge - Sweet Dee Edition   \n4   image_5.png  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n\n       humour          sarcasm       offensive      motivational  \\\n0   hilarious          general   not_offensive  not_motivational   \n1   not_funny          general   not_offensive      motivational   \n2  very_funny    not_sarcastic   not_offensive  not_motivational   \n3  very_funny  twisted_meaning  very_offensive      motivational   \n4   hilarious     very_twisted  very_offensive  not_motivational   \n\n  overall_sentiment  \n0     very_positive  \n1     very_positive  \n2          positive  \n3          positive  \n4           neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_1.jpg</td>\n      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_2.jpeg</td>\n      <td>The best of #10 YearChallenge! Completed in le...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_3.JPG</td>\n      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_4.png</td>\n      <td>10 Year Challenge - Sweet Dee Edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_5.png</td>\n      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"import re\n\ndef clean_text(text):\n    # Remove @usernames\n    text = re.sub(r'@\\w+', '', text)\n    \n    # Remove emails\n    text = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)\n    \n    # Convert to lowercase\n    text = text.lower()\n    \n    # Remove all symbols except spaces and alphanumeric characters\n    text = re.sub(r'[^a-z0-9\\s]', '', text)\n    \n    # Remove extra spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.422088Z","iopub.execute_input":"2025-02-09T17:49:52.422271Z","iopub.status.idle":"2025-02-09T17:49:52.426254Z","shell.execute_reply.started":"2025-02-09T17:49:52.422256Z","shell.execute_reply":"2025-02-09T17:49:52.425496Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"df2 = df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.427509Z","iopub.execute_input":"2025-02-09T17:49:52.427764Z","iopub.status.idle":"2025-02-09T17:49:52.438710Z","shell.execute_reply.started":"2025-02-09T17:49:52.427746Z","shell.execute_reply":"2025-02-09T17:49:52.437908Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"df2['text_corrected'] = df2['text_corrected'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.439604Z","iopub.execute_input":"2025-02-09T17:49:52.439892Z","iopub.status.idle":"2025-02-09T17:49:52.535414Z","shell.execute_reply.started":"2025-02-09T17:49:52.439866Z","shell.execute_reply":"2025-02-09T17:49:52.534861Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.536090Z","iopub.execute_input":"2025-02-09T17:49:52.536269Z","iopub.status.idle":"2025-02-09T17:49:52.545586Z","shell.execute_reply.started":"2025-02-09T17:49:52.536254Z","shell.execute_reply":"2025-02-09T17:49:52.544599Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"     image_name                                     text_corrected  \\\n0   image_1.jpg  look there my friend lightyear now all sohalik...   \n1  image_2.jpeg  the best of 10 yearchallenge completed in less...   \n2   image_3.JPG  sam thorne follow follow saw everyone posting ...   \n3   image_4.png                10 year challenge sweet dee edition   \n4   image_5.png  10 year challenge with no filter 47 hilarious ...   \n\n       humour          sarcasm       offensive      motivational  \\\n0   hilarious          general   not_offensive  not_motivational   \n1   not_funny          general   not_offensive      motivational   \n2  very_funny    not_sarcastic   not_offensive  not_motivational   \n3  very_funny  twisted_meaning  very_offensive      motivational   \n4   hilarious     very_twisted  very_offensive  not_motivational   \n\n  overall_sentiment  \n0     very_positive  \n1     very_positive  \n2          positive  \n3          positive  \n4           neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_1.jpg</td>\n      <td>look there my friend lightyear now all sohalik...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_2.jpeg</td>\n      <td>the best of 10 yearchallenge completed in less...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>very_positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_3.JPG</td>\n      <td>sam thorne follow follow saw everyone posting ...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_4.png</td>\n      <td>10 year challenge sweet dee edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_5.png</td>\n      <td>10 year challenge with no filter 47 hilarious ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:52.546401Z","iopub.execute_input":"2025-02-09T17:49:52.546670Z","iopub.status.idle":"2025-02-09T17:49:53.646784Z","shell.execute_reply.started":"2025-02-09T17:49:52.546650Z","shell.execute_reply":"2025-02-09T17:49:53.646077Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def remove_stopwords(text, custom_stopwords=None):\n    # Load default stopwords\n    stop_words = set(stopwords.words('english'))\n    stop_words.update({'follow'})\n\n    # Remove stopwords\n    filtered_text = ' '.join(word for word in text.split() if word not in stop_words)\n    \n    return filtered_text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:53.647569Z","iopub.execute_input":"2025-02-09T17:49:53.647960Z","iopub.status.idle":"2025-02-09T17:49:53.652084Z","shell.execute_reply.started":"2025-02-09T17:49:53.647922Z","shell.execute_reply":"2025-02-09T17:49:53.651238Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"df2['text_corrected'] = df2['text_corrected'].apply(remove_stopwords)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:53.652812Z","iopub.execute_input":"2025-02-09T17:49:53.653058Z","iopub.status.idle":"2025-02-09T17:49:54.401382Z","shell.execute_reply.started":"2025-02-09T17:49:53.653038Z","shell.execute_reply":"2025-02-09T17:49:54.400788Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df2['overall_sentiment'] = df2['overall_sentiment'].replace({'very_positive': 2, 'positive': 2, 'negative': 0, 'very_negative': 0, 'neutral': 1})\ndf2['overall_sentiment'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:54.402118Z","iopub.execute_input":"2025-02-09T17:49:54.402354Z","iopub.status.idle":"2025-02-09T17:49:54.418324Z","shell.execute_reply.started":"2025-02-09T17:49:54.402334Z","shell.execute_reply":"2025-02-09T17:49:54.417566Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-15-86f3814db7b8>:1: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df2['overall_sentiment'] = df2['overall_sentiment'].replace({'very_positive': 2, 'positive': 2, 'negative': 0, 'very_negative': 0, 'neutral': 1})\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"overall_sentiment\n2    4156\n1    2200\n0     631\nName: count, dtype: int64"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:54.419191Z","iopub.execute_input":"2025-02-09T17:49:54.419390Z","iopub.status.idle":"2025-02-09T17:49:54.428315Z","shell.execute_reply.started":"2025-02-09T17:49:54.419374Z","shell.execute_reply":"2025-02-09T17:49:54.427428Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"     image_name                                     text_corrected  \\\n0   image_1.jpg  look friend lightyear sohalikut trend play 10 ...   \n1  image_2.jpeg  best 10 yearchallenge completed less 4 years k...   \n2   image_3.JPG  sam thorne saw everyone posting 2009 vs 2019 p...   \n3   image_4.png                10 year challenge sweet dee edition   \n4   image_5.png  10 year challenge filter 47 hilarious 10 year ...   \n\n       humour          sarcasm       offensive      motivational  \\\n0   hilarious          general   not_offensive  not_motivational   \n1   not_funny          general   not_offensive      motivational   \n2  very_funny    not_sarcastic   not_offensive  not_motivational   \n3  very_funny  twisted_meaning  very_offensive      motivational   \n4   hilarious     very_twisted  very_offensive  not_motivational   \n\n   overall_sentiment  \n0                  2  \n1                  2  \n2                  2  \n3                  2  \n4                  1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_name</th>\n      <th>text_corrected</th>\n      <th>humour</th>\n      <th>sarcasm</th>\n      <th>offensive</th>\n      <th>motivational</th>\n      <th>overall_sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>image_1.jpg</td>\n      <td>look friend lightyear sohalikut trend play 10 ...</td>\n      <td>hilarious</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>image_2.jpeg</td>\n      <td>best 10 yearchallenge completed less 4 years k...</td>\n      <td>not_funny</td>\n      <td>general</td>\n      <td>not_offensive</td>\n      <td>motivational</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>image_3.JPG</td>\n      <td>sam thorne saw everyone posting 2009 vs 2019 p...</td>\n      <td>very_funny</td>\n      <td>not_sarcastic</td>\n      <td>not_offensive</td>\n      <td>not_motivational</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>image_4.png</td>\n      <td>10 year challenge sweet dee edition</td>\n      <td>very_funny</td>\n      <td>twisted_meaning</td>\n      <td>very_offensive</td>\n      <td>motivational</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>image_5.png</td>\n      <td>10 year challenge filter 47 hilarious 10 year ...</td>\n      <td>hilarious</td>\n      <td>very_twisted</td>\n      <td>very_offensive</td>\n      <td>not_motivational</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import DistilBertTokenizer, DistilBertModel\nfrom transformers import ViTImageProcessor, ViTModel\nfrom PIL import Image, ImageFile\nimport pandas as pd\nfrom sklearn.metrics import f1_score\nfrom sklearn.decomposition import PCA\nimport torch.optim as optim\nimport numpy as np\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:49:54.428967Z","iopub.execute_input":"2025-02-09T17:49:54.429159Z","iopub.status.idle":"2025-02-09T17:50:11.791446Z","shell.execute_reply.started":"2025-02-09T17:49:54.429142Z","shell.execute_reply":"2025-02-09T17:50:11.790568Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Configuration\nTEXT_MODEL_NAME = 'distilbert-base-uncased'\nIMAGE_MODEL_NAME = 'google/vit-base-patch16-224'\nMAX_LENGTH = 128\nBATCH_SIZE = 32\nEPOCHS = 10\nLEARNING_RATE = 2e-5\nPCA_COMPONENTS = 256  # Reduce feature dimensions\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:50:11.792349Z","iopub.execute_input":"2025-02-09T17:50:11.792987Z","iopub.status.idle":"2025-02-09T17:50:11.868549Z","shell.execute_reply.started":"2025-02-09T17:50:11.792952Z","shell.execute_reply":"2025-02-09T17:50:11.867588Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Initialize processors\ntext_tokenizer = DistilBertTokenizer.from_pretrained(TEXT_MODEL_NAME)\nimage_processor = ViTImageProcessor.from_pretrained(IMAGE_MODEL_NAME)\ntext_model = DistilBertModel.from_pretrained(TEXT_MODEL_NAME).to(DEVICE)\nimage_model = ViTModel.from_pretrained(IMAGE_MODEL_NAME).to(DEVICE)\n\n# Freeze transformers to avoid recomputation\ntext_model.eval()\nimage_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:50:11.869616Z","iopub.execute_input":"2025-02-09T17:50:11.869943Z","iopub.status.idle":"2025-02-09T17:50:16.965477Z","shell.execute_reply.started":"2025-02-09T17:50:11.869912Z","shell.execute_reply":"2025-02-09T17:50:16.964617Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"226c52f096e24aa39819ab0ec95e4337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"489f09b2b9b242bd8e22ab536e7c9017"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"519de68ccef94b11a024797a280f843a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18b7f478f85f4aa58ce2ec9849050a6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f820c17bd2c34a5fa00c3a62c190772e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40509ac26dc04f158c90cd5b34641f2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"630e6350d3464f9595329d1abdf96c32"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26c5ac18de36456db7281d8ac2b8b313"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['vit.pooler.dense.bias', 'vit.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"ViTModel(\n  (embeddings): ViTEmbeddings(\n    (patch_embeddings): ViTPatchEmbeddings(\n      (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n    )\n    (dropout): Dropout(p=0.0, inplace=False)\n  )\n  (encoder): ViTEncoder(\n    (layer): ModuleList(\n      (0-11): 12 x ViTLayer(\n        (attention): ViTSdpaAttention(\n          (attention): ViTSdpaSelfAttention(\n            (query): Linear(in_features=768, out_features=768, bias=True)\n            (key): Linear(in_features=768, out_features=768, bias=True)\n            (value): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (output): ViTSelfOutput(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (intermediate): ViTIntermediate(\n          (dense): Linear(in_features=768, out_features=3072, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): ViTOutput(\n          (dense): Linear(in_features=3072, out_features=768, bias=True)\n          (dropout): Dropout(p=0.0, inplace=False)\n        )\n        (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n    )\n  )\n  (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n  (pooler): ViTPooler(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"def preprocess_data(dataframe):\n    texts = dataframe['text_corrected'].tolist()\n    image_dir = \"/kaggle/input/multimodal-sentiment/Multimodal_dataset_assignment3/images\"\n    image_paths = dataframe['image_name'].apply(lambda name: os.path.join(image_dir, name))\n    # image_paths = dataframe['image_path'].tolist()\n    labels = torch.tensor(dataframe[['overall_sentiment']].values, dtype=torch.float)\n    \n    text_features, image_features = [], []\n    \n    with torch.no_grad():\n        for text, image_path in zip(texts, image_paths):\n            text_inputs = text_tokenizer(text, max_length=MAX_LENGTH, padding='max_length', truncation=True, return_tensors='pt').to(DEVICE)\n            text_output = text_model(**text_inputs).last_hidden_state[:, 0, :].cpu().numpy()\n\n            ImageFile.LOAD_TRUNCATED_IMAGES = True\n            image = Image.open(image_path).convert('RGB')\n            image_inputs = image_processor(images=image, return_tensors='pt').to(DEVICE)\n            image_output = image_model(**image_inputs).last_hidden_state[:, 0, :].cpu().numpy()\n            \n            text_features.append(text_output.squeeze())\n            image_features.append(image_output.squeeze())\n    \n    return np.array(text_features), np.array(image_features), labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:50:16.966436Z","iopub.execute_input":"2025-02-09T17:50:16.966705Z","iopub.status.idle":"2025-02-09T17:50:16.973048Z","shell.execute_reply.started":"2025-02-09T17:50:16.966685Z","shell.execute_reply":"2025-02-09T17:50:16.972390Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class MemeDataset(Dataset):\n    def __init__(self, text_features, image_features, labels):\n        self.text_features = text_features\n        self.image_features = image_features\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.text_features)\n\n    def __getitem__(self, idx):\n        return {\n            'text_features': torch.tensor(self.text_features[idx], dtype=torch.float),\n            'image_features': torch.tensor(self.image_features[idx], dtype=torch.float),\n            'labels': self.labels[idx]\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:50:16.973731Z","iopub.execute_input":"2025-02-09T17:50:16.973914Z","iopub.status.idle":"2025-02-09T17:50:16.988544Z","shell.execute_reply.started":"2025-02-09T17:50:16.973896Z","shell.execute_reply":"2025-02-09T17:50:16.987944Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"class MultimodalModel(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__()\n        self.fc_overall = nn.Linear(input_dim, 3)\n        self.dropout = nn.Dropout(0.1)\n        # self.sigmoid = nn.Sigmoid()\n\n    def forward(self, text_features, image_features):\n        combined = torch.cat([text_features, image_features], dim=1)\n        combined = self.dropout(combined)\n        \n        # combined = self.sigmoid(self.fc_overall(combined))\n        logits = self.fc_overall(combined)\n        \n        return logits\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:50:16.989315Z","iopub.execute_input":"2025-02-09T17:50:16.989593Z","iopub.status.idle":"2025-02-09T17:50:17.001206Z","shell.execute_reply.started":"2025-02-09T17:50:16.989572Z","shell.execute_reply":"2025-02-09T17:50:17.000388Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def evaluate(model, loader, device):\n    model.eval()\n    overall_preds, overall_labels = [], []\n    \n    with torch.no_grad():\n        for batch in loader:\n            text_features = batch['text_features'].to(device)\n            image_features = batch['image_features'].to(device)\n            labels = batch['labels'].cpu().numpy()\n            # labels = labels + 1  # Shift labels to range [0, 1, 2]\n            \n            outputs = model(text_features, image_features).cpu().numpy()\n            preds = outputs.argmax(axis=1)  # Use `axis=1` for NumPy array\n            # preds_final = [p - 1 for p in preds]  # Convert (0,1,2) -> (-1,0,1)\n            \n            overall_preds.extend(preds)\n            \n            overall_labels.extend(labels)\n            # print(preds,\"   \",labels)\n    metrics = {\n        'overall_f1': f1_score(overall_labels, overall_preds, average='macro')\n    }\n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:50:17.004074Z","iopub.execute_input":"2025-02-09T17:50:17.004289Z","iopub.status.idle":"2025-02-09T17:50:17.015703Z","shell.execute_reply.started":"2025-02-09T17:50:17.004270Z","shell.execute_reply":"2025-02-09T17:50:17.014998Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Split dataset\ntrain_df, test_df = train_test_split(df2, test_size=0.2, random_state=42)\n\ntrain_text, train_image, train_labels = preprocess_data(train_df)\nval_text, test_image, test_labels = preprocess_data(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:50:17.016911Z","iopub.execute_input":"2025-02-09T17:50:17.017188Z","iopub.status.idle":"2025-02-09T17:53:53.435870Z","shell.execute_reply.started":"2025-02-09T17:50:17.017158Z","shell.execute_reply":"2025-02-09T17:53:53.435092Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/PIL/Image.py:1054: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"pca = PCA(n_components=PCA_COMPONENTS)\ntrain_text = pca.fit_transform(train_text)\ntrain_image = pca.fit_transform(train_image)\nval_image = pca.transform(test_image)\nval_text = pca.transform(val_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:53:53.436780Z","iopub.execute_input":"2025-02-09T17:53:53.437024Z","iopub.status.idle":"2025-02-09T17:53:54.127950Z","shell.execute_reply.started":"2025-02-09T17:53:53.437003Z","shell.execute_reply":"2025-02-09T17:53:54.127023Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# Create datasets\ntrain_dataset = MemeDataset(train_text, train_image, train_labels)\nval_dataset = MemeDataset(val_text, val_image, test_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:53:54.128748Z","iopub.execute_input":"2025-02-09T17:53:54.128985Z","iopub.status.idle":"2025-02-09T17:53:54.132725Z","shell.execute_reply.started":"2025-02-09T17:53:54.128965Z","shell.execute_reply":"2025-02-09T17:53:54.131838Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:53:54.133601Z","iopub.execute_input":"2025-02-09T17:53:54.133850Z","iopub.status.idle":"2025-02-09T17:53:54.151573Z","shell.execute_reply.started":"2025-02-09T17:53:54.133829Z","shell.execute_reply":"2025-02-09T17:53:54.150771Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"model = MultimodalModel(input_dim=PCA_COMPONENTS * 2).to(DEVICE)\noptimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:53:54.152423Z","iopub.execute_input":"2025-02-09T17:53:54.152725Z","iopub.status.idle":"2025-02-09T17:53:54.163461Z","shell.execute_reply.started":"2025-02-09T17:53:54.152697Z","shell.execute_reply":"2025-02-09T17:53:54.162630Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"model.train()\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    for batch in train_loader:\n            optimizer.zero_grad()\n            \n            text_features = batch['text_features'].to(DEVICE)\n            image_features = batch['image_features'].to(DEVICE)\n            labels = batch[\"labels\"].squeeze().long().to(DEVICE)\n\n            outputs = model(text_features, image_features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n        \n    val_metrics = evaluate(model, val_loader, DEVICE)\n    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n    print(f\"Train Loss: {total_loss/len(train_loader):.4f}\")\n    print(f\"Val F1 Scores - Overall: {val_metrics['overall_f1']:.4f}\")\nval_metrics = evaluate(model, val_loader, DEVICE)\ncheckpoint = {\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'loss': loss,\n                'val_f1': val_metrics['overall_f1']\n            }\n\ntorch.save(checkpoint, 'checkpoint_TaskA.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:53:54.164329Z","iopub.execute_input":"2025-02-09T17:53:54.164578Z","iopub.status.idle":"2025-02-09T17:53:58.145510Z","shell.execute_reply.started":"2025-02-09T17:53:54.164554Z","shell.execute_reply":"2025-02-09T17:53:58.144666Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\nTrain Loss: 1.1929\nVal F1 Scores - Overall: 0.2998\nEpoch 2/10\nTrain Loss: 1.1773\nVal F1 Scores - Overall: 0.3019\nEpoch 3/10\nTrain Loss: 1.1703\nVal F1 Scores - Overall: 0.2999\nEpoch 4/10\nTrain Loss: 1.1637\nVal F1 Scores - Overall: 0.2989\nEpoch 5/10\nTrain Loss: 1.1573\nVal F1 Scores - Overall: 0.2987\nEpoch 6/10\nTrain Loss: 1.1516\nVal F1 Scores - Overall: 0.3005\nEpoch 7/10\nTrain Loss: 1.1454\nVal F1 Scores - Overall: 0.2963\nEpoch 8/10\nTrain Loss: 1.1397\nVal F1 Scores - Overall: 0.2959\nEpoch 9/10\nTrain Loss: 1.1341\nVal F1 Scores - Overall: 0.2971\nEpoch 10/10\nTrain Loss: 1.1290\nVal F1 Scores - Overall: 0.2946\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"checkpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-09T17:53:58.146435Z","iopub.execute_input":"2025-02-09T17:53:58.146782Z","iopub.status.idle":"2025-02-09T17:53:58.370912Z","shell.execute_reply.started":"2025-02-09T17:53:58.146750Z","shell.execute_reply":"2025-02-09T17:53:58.370179Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"{'epoch': 9,\n 'model_state_dict': OrderedDict([('fc_overall.weight',\n               tensor([[ 0.0308, -0.0230, -0.0118,  ...,  0.0153, -0.0310,  0.0056],\n                       [-0.0290, -0.0364,  0.0201,  ..., -0.0317, -0.0089, -0.0178],\n                       [-0.0313, -0.0430,  0.0193,  ...,  0.0227, -0.0001, -0.0013]],\n                      device='cuda:0')),\n              ('fc_overall.bias',\n               tensor([ 0.0019, -0.0293,  0.0705], device='cuda:0'))]),\n 'optimizer_state_dict': {'state': {0: {'step': tensor(1750.),\n    'exp_avg': tensor([[ 0.0504, -0.0043,  0.0113,  ..., -0.0052, -0.0118, -0.0004],\n            [-0.0039, -0.0132,  0.0117,  ...,  0.0086,  0.0207, -0.0026],\n            [-0.0466,  0.0175, -0.0230,  ..., -0.0034, -0.0089,  0.0031]],\n           device='cuda:0'),\n    'exp_avg_sq': tensor([[0.0142, 0.0041, 0.0028,  ..., 0.0014, 0.0013, 0.0013],\n            [0.0190, 0.0061, 0.0040,  ..., 0.0022, 0.0022, 0.0020],\n            [0.0288, 0.0085, 0.0057,  ..., 0.0030, 0.0030, 0.0027]],\n           device='cuda:0')},\n   1: {'step': tensor(1750.),\n    'exp_avg': tensor([ 0.2519, -0.0108, -0.2412], device='cuda:0'),\n    'exp_avg_sq': tensor([0.0496, 0.0061, 0.0568], device='cuda:0')}},\n  'param_groups': [{'lr': 2e-05,\n    'betas': (0.9, 0.999),\n    'eps': 1e-08,\n    'weight_decay': 0.01,\n    'amsgrad': False,\n    'foreach': None,\n    'maximize': False,\n    'capturable': False,\n    'differentiable': False,\n    'fused': None,\n    'params': [0, 1]}]},\n 'loss': tensor(1.1793, device='cuda:0', grad_fn=<NllLossBackward0>),\n 'val_f1': 0.29464183648833314}"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}